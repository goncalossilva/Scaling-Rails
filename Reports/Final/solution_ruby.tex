\section{Ruby} % (fold)
\label{solution:sec:ruby}
Concerning this component, the main focus was divided into four core activities. First of all, determining the real benefits of upgrading to the latest Ruby 1.9. After that, focus would shift towards porting \textit{Escolinhas.pt} to Ruby 1.9. Then, the aim was to improve YARV's GC by increasing its flexibility. Finally, Ruby's profiling and information retrieval capabilities were enhanced.

There are many interpreters being used in production environments whose characteristics were explored in Section~\ref{tech:sec:ruby}. Unfortunately, none except YARV fully support the most recent specification---1.9. It is likely that focusing on soon to be outdated solutions is not worthy. For this reason, YARV was the interpreter targeted for improvements.

Determining the performance benefits from upgrading to the most recent version of Ruby, analyzing the effort needed to accomplish it, improving one of YARV's main Rails-related bottlenecks---the garbage collector---and greatly enhancing its profiling capabilities were the general goals of the work presented in this section.

\subsection{Benchmarking}
As mentioned in Section~\ref{state:sec:ruby} the new Ruby interpreter, YARV, is supposed to significantly improve performance over its predecessor, MRI. Its first release happened more than two years ago and its adoption is still very low, despite having new features and supposedly better performance. Porting existing applications requires some development effort as there are small changes on existing functionality and behavior. Having said that Rails can easily have scalability issues, it would be expected that this version's adoption would rise considerably fast but, however, this is not currently happening.

To increase the community's awareness of the benefits of upgrading, these need to be accurately determined. The Ruby benchmark mentioned and explained on Section~\ref{solution:sec:operating_systems} was rerun to exhibit the interpreter's disparity when it comes to performance, as shown on table~\ref{tab:mri_yarv_benchmark}.

\begin{center}
\renewcommand{\arraystretch}{0.85}
\normalsize
  \begin{longtable}{l|c|c|c|c}
  \caption[MRI and YARV Benchmark Comparison]{MRI and YARV Benchmark Comparison} \label{tab:mri_yarv_benchmark} \\

  \multicolumn{1}{c|}{\textbf{Benchmark}} & \textbf{Input Size} & \textbf{MRI (1.8.7)} & \textbf{YARV (1.9.1)} & \textbf{Ratio} \\ \hline 
  \endfirsthead

  \multicolumn{5}{c}%
  {{\bfseries \tablename\ \thetable{} --- continued from previous page}} \\
  \multicolumn{1}{c|}{\textbf{Benchmark}} & \textbf{Input Size} & \textbf{MRI (1.8.7)} & \textbf{YARV (1.9.1)} & \textbf{Ratio} \\ 
  \endhead

  \multicolumn{5}{r}{{\tablename\ \thetable{} --- continued on the next page}} \\ \hline
  \endfoot

  \endlastfoot

  macro/cal & 500 & 1.990 & \textbf{0.289} & 589.28\% \\ \hline
  macro/dirp & 10000 & \textbf{0.386} & 0.393 & 2.04\% \\ \hline
  macro/gzip & 100 & 6.141 & \textbf{5.979} & 2.70\% \\ \hline
  macro/hilbert\_matrix & 10 & 0.036 & \textbf{0.002} & 1509.42\% \\ \hline
  macro/hilbert\_matrix & 20 & 0.335 & \textbf{0.031} & 984.21\% \\ \hline
  macro/hilbert\_matrix & 30 & 1.367 & \textbf{0.154} & 789.44\% \\ \hline
  macro/hilbert\_matrix & 40 & 3.866 & \textbf{0.477} & 710.68\% \\ \hline
  macro/hilbert\_matrix & 50 & 8.868 & \textbf{1.256} & 605.76\% \\ \hline
  macro/hilbert\_matrix & 60 & 18.399 & \textbf{3.024} & 508.39\% \\ \hline
  macro/list & 1000 & 0.053 & \textbf{0.026} & 102.35\% \\ \hline
  macro/list & 10000 & 7.154 & \textbf{2.758} & 159.43\% \\ \hline
  macro/mpart & 300 & 0.039 & \textbf{0.034} & 16.56\% \\ \hline
  macro/norvig\_spelling & 50 & 8.562 & ArgumentError &  \\ \hline
  macro/observ & 100000 & 0.612 & \textbf{0.360} & 69.88\% \\ \hline
  macro/parse\_log & 100 & 1.151 & \textbf{0.309} & 271.94\% \\ \hline
  macro/pi & 1000 & 0.026 & \textbf{0.024} & 7.46\% \\ \hline
  macro/pi & 10000 & 2.127 & \textbf{2.034} & 4.61\% \\ \hline
  macro/rcs & 100 & 0.753 & \textbf{0.581} & 29.70\% \\ \hline
  macro/sudoku & 1 & 10.153 & \textbf{1.661} & 511.27\% \\ \hline
  micro/app\_factorial & 5000 & StackError & 0.037 &  \\ \hline
  micro/app\_fib & 30 & 1.587 & \textbf{0.189} & 741.29\% \\ \hline
  micro/app\_fib & 35 & 17.854 & \textbf{2.099} & 750.68\% \\ \hline
  micro/app\_mandelbrot & 1 & 1.899 & \textbf{0.277} & 585.27\% \\ \hline
  micro/app\_pentomino & 1 & SignalException & 24.784 &  \\ \hline
  micro/app\_tak & 7 & 1.173 & \textbf{0.143} & 719.77\% \\ \hline
  micro/app\_tak & 8 & 3.405 & \textbf{0.414} & 722.62\% \\ \hline
  micro/app\_tak & 9 & 8.910 & \textbf{1.091} & 716.51\% \\ \hline
  micro/app\_tarai & 3 & 3.873 & \textbf{0.492} & 686.81\% \\ \hline
  micro/app\_tarai & 4 & 4.670 & \textbf{0.604} & 673.22\% \\ \hline
  micro/app\_tarai & 5 & 5.654 & \textbf{0.731} & 672.95\% \\ \hline
  micro/binary\_trees & 1 & 54.757 & \textbf{12.500} & 338.06\% \\ \hline
  micro/count\_multithreaded & 1 & \textbf{0.004} & 0.006 & 40.88\% \\ \hline
  micro/count\_multithreaded & 2 & \textbf{0.009} & 0.012 & 41.65\% \\ \hline
  micro/count\_multithreaded & 4 & \textbf{0.017} & 0.025 & 45.27\% \\ \hline
  micro/count\_multithreaded & 8 & \textbf{0.034} & 0.049 & 46.36\% \\ \hline
  micro/count\_multithreaded & 16 & \textbf{0.067} & 0.100 & 48.25\% \\ \hline
  micro/count\_shared\_thread & 1 & \textbf{0.044} & 0.061 & 39.60\% \\ \hline
  micro/count\_shared\_thread & 2 & \textbf{0.044} & 0.061 & 39.45\% \\ \hline
  micro/count\_shared\_thread & 4 & \textbf{0.044} & 0.061 & 38.36\% \\ \hline
  micro/count\_shared\_thread & 8 & \textbf{0.044} & 0.062 & 40.22\% \\ \hline
  micro/count\_shared\_thread & 16 & \textbf{0.045} & 0.062 & 38.67\% \\ \hline
  micro/eval & 1000000 & \textbf{1.843} & 5.892 & 219.67\% \\ \hline
  micro/fannkuch & 6 & 0.005 & \textbf{0.003} & 54.48\% \\ \hline
  micro/fannkuch & 8 & 0.398 & \textbf{0.252} & 57.81\% \\ \hline
  micro/fannkuch & 10 & 44.995 & \textbf{29.300} & 53.57\% \\ \hline
  micro/fasta & 1000000 & 37.028 & \textbf{13.992} & 164.65\% \\ \hline
  micro/fiber\_ring & 10 & LoadError & 0.000 &  \\ \hline
  micro/fiber\_ring & 100 & LoadError & 0.018 &  \\ \hline
  micro/fiber\_ring & 1000 & LoadError & 1.724 &  \\ \hline
  micro/fractal & 5 & 4.520 & \textbf{3.004} & 50.48\% \\ \hline
  micro/gc\_array & 1 & 44.990 & \textbf{39.619} & 13.56\% \\ \hline
  micro/gc\_mb & 500000 & 0.687 & \textbf{0.173} & 297.95\% \\ \hline
  micro/gc\_mb & 1000000 & 1.513 & \textbf{0.346} & 337.27\% \\ \hline
  micro/gc\_mb & 3000000 & 3.535 & \textbf{1.087} & 225.32\% \\ \hline
  micro/gc\_string & 1 & 7.874 & \textbf{3.090} & 154.80\% \\ \hline
  micro/knucleotide & 1 & 1.396 & \textbf{0.826} & 68.93\% \\ \hline
  micro/lucas\_lehmer & 9689 & \textbf{4.019} & 4.611 & 14.73\% \\ \hline
  micro/lucas\_lehmer & 9941 & \textbf{4.342} & 4.980 & 14.68\% \\ \hline
  micro/lucas\_lehmer & 11213 & \textbf{6.174} & 7.096 & 14.93\% \\ \hline
  micro/lucas\_lehmer & 19937 & \textbf{33.143} & 38.069 & 14.87\% \\ \hline
  micro/mandelbrot & 1 & 55.460 & \textbf{30.207} & 83.60\% \\ \hline
  micro/mbari\_bogus1 & 1 & StackError & 0.008 &  \\ \hline
  micro/mergesort & 1 & 1.914 & \textbf{0.659} & 190.40\% \\ \hline
  micro/mergesort\_hongli & 3000 & 4.423 & \textbf{1.108} & 299.34\% \\ \hline
  micro/meteor\_contest & 1 & 25.352 & \textbf{7.633} & 232.14\% \\ \hline
  micro/monte\_carlo\_pi & 10000000 & 12.178 & \textbf{7.828} & 55.58\% \\ \hline
  micro/nbody & 100000 & 7.046 & \textbf{5.569} & 26.53\% \\ \hline
  micro/nsieve & 9 & 15.221 & NoMethodError &  \\ \hline
  micro/nsieve\_bits & 8 & 19.753 & \textbf{2.385} & 728.28\% \\ \hline
  micro/open\_many\_files & 50000 & \textbf{0.211} & 0.245 & 16.05\% \\ \hline
  micro/partial\_sums & 2500000 & 18.003 & \textbf{14.396} & 25.05\% \\ \hline
  micro/primes & 3000 & 5.057 & \textbf{0.012} & 43396.39\% \\ \hline
  micro/primes & 30000 & SignalException & 0.128 &  \\ \hline
  micro/primes & 300000 & SignalException & 1.404 &  \\ \hline
  micro/primes & 3000000 & SignalException & 17.761 &  \\ \hline
  micro/quicksort & 1 & 7.116 & \textbf{1.432} & 396.99\% \\ \hline
  micro/read\_large & 100 & 6.337 & \textbf{2.441} & 159.65\% \\ \hline
  micro/regex\_dna & 20 & \textbf{2.644} & 2.797 & 5.78\% \\ \hline
  micro/reverse\_compliment & 1 & 3.702 & \textbf{2.782} & 33.08\% \\ \hline
  micro/simple\_connect & 1 & \textbf{0.134} & 0.216 & 60.82\% \\ \hline
  micro/simple\_connect & 100 & \textbf{0.143} & 0.143 & 0.40\% \\ \hline
  micro/simple\_connect & 500 & 0.175 & \textbf{0.173} & 0.72\% \\ \hline
  micro/simple\_server & 1 & \textbf{0.134} & 0.138 & 3.02\% \\ \hline
  micro/simple\_server & 100 & \textbf{0.136} & 0.138 & 1.89\% \\ \hline
  micro/simple\_server & 100000 & 1.427 & \textbf{1.411} & 1.12\% \\ \hline
  micro/so\_ackermann & 7 & 0.494 & \textbf{0.059} & 734.56\% \\ \hline
  micro/so\_ackermann & 9 & StackError & 0.957 &  \\ \hline
  micro/so\_array & 9000 & 6.867 & \textbf{1.938} & 254.26\% \\ \hline
  micro/so\_count\_words & 100 & \textbf{2.408} & 2.831 & 17.52\% \\ \hline
  micro/so\_exception & 500000 & \textbf{8.009} & 8.324 & 3.93\% \\ \hline
  micro/so\_lists & 1000 & 8.649 & \textbf{4.483} & 92.91\% \\ \hline
  micro/so\_lists\_small & 1000 & 1.741 & \textbf{0.905} & 92.30\% \\ \hline
  micro/so\_matrix & 60 & 1.924 & \textbf{0.592} & 224.80\% \\ \hline
  micro/so\_object & 500000 & 1.424 & \textbf{0.413} & 244.44\% \\ \hline
  micro/so\_object & 1000000 & 2.825 & \textbf{0.817} & 245.87\% \\ \hline
  micro/so\_object & 1500000 & 4.265 & \textbf{1.224} & 248.29\% \\ \hline
  micro/so\_sieve & 4000 & 54.784 & \textbf{8.650} & 533.31\% \\ \hline
  micro/socket\_transfer\_1mb & 10000 & 0.353 & \textbf{0.306} & 15.40\% \\ \hline
  micro/socket\_transfer\_1mb & 1000000 & 0.356 & \textbf{0.304} & 17.28\% \\ \hline
  micro/spectral\_norm & 100 & 0.932 & \textbf{0.233} & 300.57\% \\ \hline
  micro/string\_concat & 10000000 & 5.655 & \textbf{1.525} & 270.78\% \\ \hline
  micro/sum\_file & 100 & 9.920 & \textbf{3.817} & 159.90\% \\ \hline
  micro/word\_anagrams & 1 & 7.750 & \textbf{3.775} & 105.31\% \\ \hline
  micro/write\_large & 100 & 0.157 & \textbf{0.147} & 6.51\% \\ \hline
  rdoc/against\_itself\_darkfish & 1 & 13.118 & \textbf{6.991} & 87.65\% \\ \hline
  rdoc/against\_itself\_ri & 1 & 12.854 & \textbf{5.580} & 130.35\% \\ \hline
  \textbf{Total} & \multicolumn{1}{l|}{\textbf{}} & \textbf{679.880} & \textbf{325.398} & \textbf{108.94\%} \\
  \end{longtable}
\end{center}

As expected, YARV shows excellent results on this benchmark, in comparison with MRI. It is approximately 109\% faster than the older 1.8 interpreter. Concerning memory usage, MRI used an average 46,34MB of memory during the whole benchmark while YARV only consumed 30,81MB. Regarding specific tests, YARV is generally faster by there is a notable exception: threads. As explained in Section~\ref{tech:sec:ruby}, MRI uses green threads while YARV supports native threads. Green threads emulate multithreaded environments but there is no parallel computing at all since they do not use multiple processing units. They have, however, a significantly low spawning overhead, contrary to native threads. The previously shown threading tests, where MRI yielded better results than YARV, are very fast. For this reason, the overhead of spawning native threads for such a small test duration had a considerable impact in the overall performance of YARV, resulting in poorer performance. Heavier tests would likely yield different results, given that native threads are actually capable of running on different processing units.

Notwithstanding this exception, YARV shows significant performance improvements overall and this fact is likely to motivate developers to switch to this version.

It is also critical to determine the performance differences on a real Rails application. As this is also related to the web server in use, this subject will be researched throughly on Section~\ref{solution:sec:rails_web_servers}.

\subsection{Development}
The development phase involved many distinct activities. The details on each one of them are explored and explained below.

\subsubsection{Porting Escolinhas.pt to Ruby 1.9}
\textit{Escolinhas.pt} has over 70 models and database tables, over 130000 lines of Ruby code, uses over 40 Rails plugins and gems, and there are currently more than 10 development branches. It is a heavy and complex full-featured application, making it a great subject to evaluate the effort needed to port an application to Ruby 1.9.

This process was fairly simple. The main issue was related to character encodings in Portuguese literal strings on the source code and database, which emerged from the heavy changes regarding encoding handling in Ruby 1.9. A patch to fix literal string encoding can be found on appendix~\ref{ap:ruby19_encoding_patch}. Ruby 1.9 also requires developers to set the default encoding for each file inside a comment in the beginning, or else it will use the default ASCII-8BIT which has its known limitations. A task was developed to manage the default encoding in all files of a Ruby project and is presented on appendix~\ref{ap:ruby19_encoding_task}.

Other issues were mainly related to extracted functionality and syntax changes. The most common ones were:
\begin{itemize}
  \item \textit{Object.type} changed to \textit{Object.class.name};
  \item The \textit{String} class no longer has the \textit{normalize} method;
  \item The case statement no longer supports ``:'' to separate the match word from the action to be taken.
\end{itemize}

As mentioned before, porting \textit{Escolinhas.pt} to Ruby 1.9 was a very fast and simple process. Measuring the effort in time units, porting to 1.9 accounted for less then 0.1\% of all the development endeavor. All changes were simple and straightforward. Taking the aforementioned performance benefits into account, porting an application to Ruby 1.9 is likely to be very worthy on most projects.

On a related matter, a considerable amount of effort is being made by the Ruby on Rails development team to automatically manage the encoding of Ruby files in Rails 3. Given that Ruby's encoding changes accounted for most part of the effort needed to port \textit{Escolinhas.pt} to Ruby 1.9, porting an application under Rails 3 should generally be effortless, as this version natively handles most of Ruby's encoding-related quirks.

\subsubsection{Increasing YARV's GC Flexibility}
Ruby Enterprise Edition, as exposed in Section~\ref{tech:sec:ruby}, allows users to set some GC parameters, providing adaptive performance. As mentioned in Section~\ref{state:sec:ruby}, many platforms benefit from this flexibility by adapting many GC parameters to their applications. Adding this functionality to YARV was the goal, and it currently supports the following settings:
\begin{description}
  \item[RUBY\_HEAP\_MIN\_SLOTS,] the initial number of heap slots. It also represents the minimum number of slots at all times (default: 10000);
  \item[RUBY\_HEAP\_SLOTS\_INCREMENT,] the number of new slots to allocate when all initial slots are used (default: 10000);
  \item[RUBY\_HEAP\_SLOTS\_GROWTH\_FACTOR,] the multiplicator used next time Ruby needs new heap slots (default: 1.8, meaning it will allocate 18000 new slots if the default settings are in use);
  \item[RUBY\_GC\_MALLOC\_LIMIT,] the number of C data structures that can be allocated before triggering the garbage collector. This one is very important since the default value makes the GC run when there are still empty heap slots, mainly due to Rails frequently allocating and deallocating large amounts of data (default: 8000000);
  \item[RUBY\_HEAP\_FREE\_MIN,] the number of free slots that should be present after GC finishes running. In case there are fewer slots than those defined, it will allocate new ones according to value of \textit{RUBY\_HEAP\_SLOTS\_INCREMENT} and the value of the previously mentioned \textit{RUBY\_HEAP\_SLOTS\_GROWTH\_FACTOR} parameters (default: 4096).
\end{description}
The developer can configure these options in the system's environment and the Ruby interpreter will detect and apply them to its internal configuration.

Appendix~\ref{ap:ruby19_configuration} contains a sample script which launches Ruby with a user-defined configuration. The parameters indicate that Ruby should start with more initial slots, have a higher threshold for triggering the GC and have a less exponential memory growth---1,1---instead of using the default 1,8 coefficient.

A benchmark comparing these configurations with the default ones was conducted and is presented on table~\ref{tab:flexible_yarv_benchmark}.
\begin{center}
\renewcommand{\arraystretch}{0.85}
\normalsize
  \begin{longtable}{l|c|c|c|c}
  \caption[Flexible YARV Benchmark]{Flexible YARV Benchmark} \label{tab:flexible_yarv_benchmark} \\

  \multicolumn{1}{c|}{\textbf{Benchmark}} & \textbf{Input Size} & \textbf{YARV} & \textbf{YARV (tweaked)} & \textbf{Ratio} \\ \hline 
  \endfirsthead

  \multicolumn{5}{c}%
  {{\bfseries \tablename\ \thetable{} --- continued from previous page}} \\
  \multicolumn{1}{c|}{\textbf{Benchmark}} & \textbf{Input Size} & \textbf{1.9.1 (Gentoo)} & \textbf{1.9.1(FreeBSD)} & \textbf{Ratio} \\ 
  \endhead

  \multicolumn{5}{r}{{\tablename\ \thetable{} --- continued on the next page}} \\ \hline
  \endfoot

  \endlastfoot

  macro/cal & 500 & 0.289 & \textbf{0.253} & 14.03\% \\ \hline
  macro/dirp & 10000 & \textbf{0.393} & 0.454 & 15.38\% \\ \hline
  macro/gzip & 100 & \textbf{5.979} & 5.991 & 0.20\% \\ \hline
  macro/hilbert\_matrix & 10 & 0.002 & \textbf{0.002} & 12.81\% \\ \hline
  macro/hilbert\_matrix & 20 & 0.031 & \textbf{0.027} & 13.03\% \\ \hline
  macro/hilbert\_matrix & 30 & 0.154 & \textbf{0.133} & 15.65\% \\ \hline
  macro/hilbert\_matrix & 40 & 0.477 & \textbf{0.399} & 19.47\% \\ \hline
  macro/hilbert\_matrix & 50 & 1.256 & \textbf{1.022} & 22.95\% \\ \hline
  macro/hilbert\_matrix & 60 & 3.024 & \textbf{2.296} & 31.72\% \\ \hline
  macro/list & 1000 & 0.026 & \textbf{0.025} & 7.04\% \\ \hline
  macro/list & 10000 & 2.758 & \textbf{1.418} & 94.42\% \\ \hline
  macro/mpart & 300 & 0.034 & \textbf{0.032} & 4.63\% \\ \hline
  macro/norvig\_spelling & 50 & ArgumentError & 4.781 &  \\ \hline
  macro/observ & 100000 & 0.360 & \textbf{0.336} & 7.14\% \\ \hline
  macro/parse\_log & 100 & \textbf{0.309} & 0.460 & 48.72\% \\ \hline
  macro/pi & 1000 & 0.024 & \textbf{0.023} & 3.31\% \\ \hline
  macro/pi & 10000 & 2.034 & \textbf{1.979} & 2.77\% \\ \hline
  macro/rcs & 100 & 0.581 & \textbf{0.491} & 18.16\% \\ \hline
  macro/sudoku & 1 & 1.661 & \textbf{1.570} & 5.77\% \\ \hline
  micro/app\_factorial & 5000 & 0.037 & \textbf{0.036} & 3.83\% \\ \hline
  micro/app\_fib & 30 & 0.189 & \textbf{0.177} & 6.47\% \\ \hline
  micro/app\_fib & 35 & 2.099 & \textbf{1.954} & 7.43\% \\ \hline
  micro/app\_mandelbrot & 1 & 0.277 & \textbf{0.242} & 14.64\% \\ \hline
  micro/app\_pentomino & 1 & 24.784 & \textbf{23.880} & 3.79\% \\ \hline
  micro/app\_tak & 7 & 0.143 & \textbf{0.138} & 3.93\% \\ \hline
  micro/app\_tak & 8 & 0.414 & \textbf{0.395} & 4.72\% \\ \hline
  micro/app\_tak & 9 & 1.091 & \textbf{1.054} & 3.58\% \\ \hline
  micro/app\_tarai & 3 & 0.492 & \textbf{0.485} & 1.54\% \\ \hline
  micro/app\_tarai & 4 & 0.604 & \textbf{0.585} & 3.31\% \\ \hline
  micro/app\_tarai & 5 & 0.731 & \textbf{0.708} & 3.27\% \\ \hline
  micro/binary\_trees & 1 & 12.500 & \textbf{11.870} & 5.30\% \\ \hline
  micro/count\_multithreaded & 1 & 0.006 & \textbf{0.006} & 3.11\% \\ \hline
  micro/count\_multithreaded & 2 & 0.012 & \textbf{0.012} & 3.74\% \\ \hline
  micro/count\_multithreaded & 4 & 0.025 & \textbf{0.024} & 4.68\% \\ \hline
  micro/count\_multithreaded & 8 & 0.049 & \textbf{0.047} & 4.26\% \\ \hline
  micro/count\_multithreaded & 16 & 0.100 & \textbf{0.095} & 4.93\% \\ \hline
  micro/count\_shared\_thread & 1 & 0.061 & \textbf{0.059} & 3.22\% \\ \hline
  micro/count\_shared\_thread & 2 & 0.061 & \textbf{0.059} & 3.06\% \\ \hline
  micro/count\_shared\_thread & 4 & 0.061 & \textbf{0.059} & 3.30\% \\ \hline
  micro/count\_shared\_thread & 8 & 0.062 & \textbf{0.059} & 5.18\% \\ \hline
  micro/count\_shared\_thread & 16 & 0.062 & \textbf{0.059} & 4.90\% \\ \hline
  micro/eval & 1000000 & \textbf{5.892} & 6.630 & 12.53\% \\ \hline
  micro/fannkuch & 6 & 0.003 & \textbf{0.003} & 8.08\% \\ \hline
  micro/fannkuch & 8 & 0.252 & \textbf{0.241} & 4.60\% \\ \hline
  micro/fannkuch & 10 & \textbf{29.300} & 29.922 & 2.12\% \\ \hline
  micro/fasta & 1000000 & 13.992 & \textbf{12.560} & 11.40\% \\ \hline
  micro/fiber\_ring & 10 & 0.000 & \textbf{0.000} & 2.96\% \\ \hline
  micro/fiber\_ring & 100 & 0.018 & \textbf{0.018} & 2.59\% \\ \hline
  micro/fiber\_ring & 1000 & 1.724 & \textbf{1.682} & 2.47\% \\ \hline
  micro/fractal & 5 & 3.004 & \textbf{2.326} & 29.12\% \\ \hline
  micro/gc\_array & 1 & 39.619 & \textbf{15.785} & 150.99\% \\ \hline
  micro/gc\_mb & 500000 & \textbf{0.173} & 0.233 & 35.07\% \\ \hline
  micro/gc\_mb & 1000000 & \textbf{0.346} & 0.470 & 35.84\% \\ \hline
  micro/gc\_mb & 3000000 & \textbf{1.087} & 1.400 & 28.84\% \\ \hline
  micro/gc\_string & 1 & 3.090 & \textbf{2.857} & 8.16\% \\ \hline
  micro/knucleotide & 1 & 0.826 & \textbf{0.737} & 12.09\% \\ \hline
  micro/lucas\_lehmer & 9689 & 4.611 & \textbf{4.436} & 3.96\% \\ \hline
  micro/lucas\_lehmer & 9941 & 4.980 & \textbf{4.792} & 3.92\% \\ \hline
  micro/lucas\_lehmer & 11213 & 7.096 & \textbf{6.830} & 3.89\% \\ \hline
  micro/lucas\_lehmer & 19937 & 38.069 & \textbf{36.632} & 3.92\% \\ \hline
  micro/mandelbrot & 1 & 30.207 & \textbf{22.877} & 32.04\% \\ \hline
  micro/mbari\_bogus1 & 1 & \textbf{0.008} & 0.008 & 4.31\% \\ \hline
  micro/mergesort & 1 & 0.659 & \textbf{0.621} & 6.16\% \\ \hline
  micro/mergesort\_hongli & 3000 & 1.108 & \textbf{1.014} & 9.26\% \\ \hline
  micro/meteor\_contest & 1 & 7.633 & \textbf{6.275} & 21.64\% \\ \hline
  micro/monte\_carlo\_pi & 10000000 & 7.828 & \textbf{6.126} & 27.78\% \\ \hline
  micro/nbody & 100000 & 5.569 & \textbf{4.634} & 20.18\% \\ \hline
  micro/nsieve\_bits & 8 & 2.385 & \textbf{2.087} & 14.28\% \\ \hline
  micro/open\_many\_files & 50000 & 0.245 & \textbf{0.214} & 14.53\% \\ \hline
  micro/partial\_sums & 2500000 & 14.396 & \textbf{12.077} & 19.20\% \\ \hline
  micro/primes & 3000 & 0.012 & \textbf{0.010} & 16.46\% \\ \hline
  micro/primes & 30000 & 0.128 & \textbf{0.113} & 12.88\% \\ \hline
  micro/primes & 300000 & 1.404 & \textbf{1.208} & 16.22\% \\ \hline
  micro/primes & 3000000 & 17.761 & \textbf{13.421} & 32.34\% \\ \hline
  micro/quicksort & 1 & 1.432 & \textbf{1.429} & 0.21\% \\ \hline
  micro/read\_large & 100 & 2.441 & \textbf{2.078} & 17.47\% \\ \hline
  micro/regex\_dna & 20 & \textbf{2.797} & 3.082 & 10.21\% \\ \hline
  micro/reverse\_compliment & 1 & 2.782 & \textbf{2.741} & 1.48\% \\ \hline
  micro/simple\_connect & 1 & 0.216 & \textbf{0.132} & 63.98\% \\ \hline
  micro/simple\_connect & 100 & 0.143 & \textbf{0.138} & 4.10\% \\ \hline
  micro/simple\_connect & 500 & 0.173 & \textbf{0.166} & 4.26\% \\ \hline
  micro/simple\_server & 1 & 0.138 & \textbf{0.131} & 5.25\% \\ \hline
  micro/simple\_server & 100 & 0.138 & \textbf{0.132} & 4.77\% \\ \hline
  micro/simple\_server & 100000 & 1.411 & \textbf{1.322} & 6.72\% \\ \hline
  micro/so\_ackermann & 7 & 0.059 & \textbf{0.052} & 12.89\% \\ \hline
  micro/so\_ackermann & 9 & 0.957 & \textbf{0.845} & 13.28\% \\ \hline
  micro/so\_array & 9000 & 1.938 & \textbf{1.832} & 5.78\% \\ \hline
  micro/so\_count\_words & 100 & \textbf{2.831} & 2.877 & 1.64\% \\ \hline
  micro/so\_exception & 500000 & \textbf{8.324} & 9.251 & 11.13\% \\ \hline
  micro/so\_lists & 1000 & 4.483 & \textbf{4.383} & 2.28\% \\ \hline
  micro/so\_lists\_small & 1000 & 0.905 & \textbf{0.884} & 2.45\% \\ \hline
  micro/so\_matrix & 60 & 0.592 & \textbf{0.553} & 7.09\% \\ \hline
  micro/so\_object & 500000 & 0.413 & \textbf{0.358} & 15.40\% \\ \hline
  micro/so\_object & 1000000 & 0.817 & \textbf{0.722} & 13.15\% \\ \hline
  micro/so\_object & 1500000 & 1.224 & \textbf{1.074} & 13.97\% \\ \hline
  micro/so\_sieve & 4000 & \textbf{8.650} & 8.710 & 0.69\% \\ \hline
  micro/socket\_transfer\_1mb & 10000 & \textbf{0.306} & 0.391 & 27.95\% \\ \hline
  micro/socket\_transfer\_1mb & 1000000 & \textbf{0.304} & 0.396 & 30.21\% \\ \hline
  micro/spectral\_norm & 100 & 0.233 & \textbf{0.193} & 20.60\% \\ \hline
  micro/string\_concat & 10000000 & \textbf{1.525} & 1.592 & 4.38\% \\ \hline
  micro/sum\_file & 100 & 3.817 & \textbf{3.483} & 9.59\% \\ \hline
  micro/word\_anagrams & 1 & \textbf{3.775} & 3.940 & 4.37\% \\ \hline
  micro/write\_large & 100 & 0.147 & \textbf{0.140} & 4.95\% \\ \hline
  rdoc/against\_itself\_darkfish & 1 & \textbf{6.991} & 7.199 & 2.97\% \\ \hline
  rdoc/against\_itself\_ri & 1 & \textbf{5.580} & 5.653 & 1.30\% \\ \hline
  rdoc/core\_darkfish & 1 & SystemExit & 66.191 &  \\ \hline
  \textbf{Total} & \multicolumn{1}{l|}{\textbf{}} & \textbf{372.219} & \textbf{323.032} & \textbf{15.23\%} \\
  \end{longtable}
\end{center}

The aforementioned parameters changed YARV's performance, having an overall improvement of $\pm$15,2\%. Since it was configured to have a less sensible threshold, garbage collection was triggered less often resulting in improved execution times. The usage of these parameters also slightly improved the average memory usage throughout all tests, lowering it from 30,81MB to 29,09MB. This is mainly due to the fact that the allocation rate is less exponential thus provoking a more linear heap growth.

The Ruby fork where this additional feature was implemented is open-source and hosted on GitHub~\footnote{\url{http://github.com/goncalossilva/ruby/}}.

\subsubsection{Storage and Retrieval of Profiling Information}
The most recent version of Ruby already possesses an embedded profiler. It records important information like the time spent in garbage collection, the number of live objects in the heap or even the total size of allocated memory, among others. Users can retrieve its current status in a properly formatted string containing all the data.

This current implementation has three main issues that can negatively impact many profiling situations. Firstly, ``string'' being the only format in which this information can be retrieved. Though being optimized for the Human eye, it is not very suited for automated processing. The second issue is related with the profiler's inability to record data accumulatively. For instance, if a given task allocates one thousand objects but triggers the GC a number of times, the developer will not be aware of those one thousand object allocations since the garbage collector will have probably freed some of them. Lastly, the profiler does not track down the number of times that the garbage collector is triggered. This information is crucial to optimize applications or code snippets since, based on what was explained in Section~\ref{state:sec:ruby}, fine-tuning an application to trigger the garbage collector less often will increase the interpreter's performance.

Given these issues, the development phase had three clear goals:
\begin{enumerate}
  \item Add the ability to retrieve profiling information in hash format;
  \item Record the accumulated number and size of data allocations;
  \item Record the number of times that the garbage collector is triggered.
\end{enumerate}

This work was developed as a series of open-source patches for the most recent Ruby versions, stable or unstable, and is hosted on GitHub~\footnote{\url{http://github.com/wycats/ruby-prof/tree/master/patches/gcdata/}}.

\subsubsection{Graphical Interface for Profiling Applications}
There are many tools available to profile Ruby and Rails applications. However, most of them record their analysis information in text. While this format suits most situations as very convenient, a graphical interface would be more appropriate in some cases. A solid example of this situation is a call stack. Albeit being acceptable to read and understand a small call stack in a console or text file, Rails applications tend to have huge call stacks which, unfortunately, are very hard to read and understand on this format.

Stephen Kaes once developed an hierarchical HTML output format for ruby-prof~\footnote{\url{http://ruby-prof.rubyforge.org/}} which is one of the most famous Ruby profilers and the only one that is officially supported in Rails. However, its development was halted and as the development of Ruby advanced this HTML printer soon became deprecated and stopped working. Users on the most recent versions of Ruby, from 1.8.7 to 1.9.2, could not use this printer to analyze the call stacks of their applications or code snippets.

The goal was to get this hierarchical HTML printer working with the latest Ruby versions. Firstly, it involved getting ruby-prof's compatibility with Ruby 1.9 increased and then porting the printer to this up-to-date version.

This work was done in collaboration with Yehuda Katz~\footnote{\url{http://yehudakatz.com/}}, one of Rails' core team members. The working printer~\footnote{\url{http://github.com/wycats/ruby-prof/blob/master/lib/ruby-prof/call_stack_printer.rb}} is part of my public ``ruby-prof'' branch on GitHub~\footnote{\url{http://github.com/wycats/ruby-prof/}}.

It hierarchically shows the call stack, being able to expand or collapse calls. It shows the total amount of time of the test, the percentage each call represents of the complete execution time and the number of times each method was called. If multiple threads ran different calls, it represents them accordingly. A percentage threshold can also be defined in order to collapse faster calls and highlight the slower ones. Finally, it uses colors to indicate each call's speed, improving bottleneck detection. An example output is shown on appendix~\ref{ap:ruby-prof_html_stack_printer}.


\subsection{Section Overview}
This section exhibited and explained the work concerning the Ruby interpreter. Regarding benchmarking, the performance differences between YARV and its predecessor, MRI, were determined. As expected, YARV overall performance is noticeably better than MRI's. Concerning development, many activities were involved. First of all, \textit{Escolinhas.pt} was ported to Ruby 1.9 to benefit from YARV's improvements. The porting effort was analyzed, concluding that it was significantly low. After that, YARV's GC flexibility was improved by creating five configuration options for adaptive performance. Initial tests were shown and by using the settings mentioned in appendix~\ref{ap:ruby19_configuration} YARV's performance increased while consuming less memory overall. YARV's internal profiler was also improved. More data is being recorded, the \textit{hash} format is now supported on result output and an HTML-based output format was incorporated, providing a graphical interface for easier analysis.

All benchmarks comparing MRI with YARV allowed determining the overall benefits of upgrading applications to YARV. Porting \textit{Escolinhas.pt} to Ruby 1.9 allowed to briefly analyze the effort needed to upgrade applications to Ruby 1.9. Adding flexibility to YARV and analyzing its performance under different configurations allowed concluding that YARV's garbage collector was improved. By recording more data and providing alternate output formats, YARV's profiling capabilities were also enhanced, completing the last of the general goals initially stated.
