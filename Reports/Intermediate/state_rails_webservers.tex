\section{Rails Webservers} % (fold)
\label{state:sec:rails_webservers}
The first Rails web server was WEBrick, publicly released in 2000. Mongrel came in 2006 and soon after Thin and Passenger followed.

\cite{ruby_webservers} did an excellent overview of some metrics that heavily contribute to web server performance. They are enumerated and explained in the following sections, along with a simple analysis of how each web server handles them.

\subsection{Data Copying}
When a server fetches a file from the disk or a back end server it usually copies it to kernel space in order to send it to the client. There are ways of sending the data directly without copying it, called \textit{zero-copy} techniques~\cite{ zero-copy_data_transfer}.

WEBrick, Mongrel and Thin neglect this issue. Passenger avoid this issue as well but, on the other hand, it passes file descriptors to worker processes which avoids sending the data to the clients through the parent web server.

\subsection{Context Switching}
This issue is related with context switching between kernel and user space and all the overhead involved in this procedure. System calls and thread exchange are some of the activities that cause context switches.

WEBrick and Mongrel highly relies on threads, which implies many context switches.  Passenger's potentiated context switches are related to process context switching, since it uses processes instead of threads. Thin efficiently handles context switches --- it does not use threads nor processes, avoiding the overhead of context switches.

\subsection{Lock Contention} 
Multiple threads or processes with shared data imply data locking from time to time. If the data is locked it will put the remaining threads or processes trying to use it on hold.

WEBrick's and Mongrel's threads share almost no data, avoiding noticeable issues related to lock contention. Neither Thin nor Passenger share data inter processes or threads, completely avoiding lock contention.

\subsection{Memory Management}
Web servers allocate and free memory frequently and Ruby's garbage collector is not very efficient for such application behavior. Web servers might counter this issue by allocating little objects and/or reusing them as much as possible.

WEBrick does not conserve memory neither reuses objects. In Mongrel, though, parser objects are reusable and string usage is kept to a minimum, getting replaced by constants. Thin also avoids using strings in detriment of constants but buffers data twice in memory before retrieving it from \textit{Rack}. Passenger does an excellent job in memory management by using the fork friendly Ruby implementation, allowing it to recycle worker processes.

\subsection{Blocking Operations}
I/O operations, as mentioned before, blocks the server until the operation finishes.

WEBrick solely relies on non-blocking I/O. Contrary, Mongrel performs all I/O in a blocking manner because of its usage of threads. Thin, on the other hand, does most of its I/O operations in a non-blocking manner and Passenger is not affected by this issue since it uses single threaded processes.

\subsection{HTTP Parsing}
The implementation of the HTTP parser greatly affects the web server performance since it is a heavy process.

WEBrick's HTTP parser is written in pure Ruby, having poor performance. Mongrel, in contrast, uses a fast and secure implementation written in C. While Thin uses a similar parser to Mongrel's one, Passenger does not do HTTP parsing and handles that responsibility to its underlying web server.

\subsection{TCP Stack}
Web servers can tune TCP operations by specifying a set of options allowed by the TCP protocol implementation.

WEBrick and Thin do not try to optimize the TCP stack while Mongrel uses two configuration options that increase the number of allowed waiting connections and \textit{TCP\_CORK} to optimize bandwith usage. Finally, these kinds of optimizations on Passenger depend on whether its underlying web server is using TCP stack optimization configurations.\\\\% FIXME: hack :|
From all the exposed Rails web servers, Passenger presents itself as the easiest to setup in a server environment~\cite{ruby_webservers} since it can be installed as a module for other easily installable web servers like Apache or Nginx.

\subsection{Benchmarks}
Some benchmarks were endured by~\cite{ruby_webservers}, whose results are showed on table~\ref{tab:webserver_benchmarks}.

\begin{table}[h!t]
  \centering
  
  \begin{tabular}{p{1.3cm}|p{1.8cm}|p{2cm}|p{2cm}|p{2cm}|p{1.3cm}|p{2cm}}
    \textsc{Test}
  & \textsc{Users}
  & \textsc{Requests}
  & \textsc{WEBrick}
  & \textsc{Mongrel}
  & \textsc{Thin}
  & \textsc{Passenger} \\
  \hline

  \multirow{3}{*}{1}
  & 10 & 1000 & 169 & 438 & 650 & 497\\
  & 100 & 1000 & 209 & 451 & 613 & 509\\
  & 1000 & 1000 & 250 & 446 & 615 & 324\\
  \hline
    
  \multirow{3}{*}{2}
  & 10 & 1000 & 115 & 309 & 365 & 305\\
  & 100 & 1000 & 165 & 299 & 350 & 316\\
  & 1000 & 1000 & 194 & 284 & 346 & 307\\
  \hline
  
  \multirow{2}{*}{3}
  & 10 & 1000 & 41 & 44 & 43 & 45\\
  & 100 & 1000 & 41 & 42 & 45 & 44\\
  \hline

  \multirow{2}{*}{4}
  & 10 & 1000 & 41 & 37 & 55 & 79\\
  & 100 & 1000 & 41 & 37 & 54 & 79\\
  \hline
  
  \multirow{2}{*}{5}
  & 10 & 1000 & 6 & 5 & 7 & 10\\
  & 100 & 1000 & 6 & 5 & 2 & 10\\
  
  \end{tabular}
  \caption{Web server benchmark results}
  \label{tab:webserver_benchmarks}
\end{table}
All tests consist in serving dynamic requests from a single Rails process. All requests are made concurrently and each web server's results are in number of requests handled per second. Test 1 is a sample ``Hello World!'' page. Test 2 fetches a database record and renders it as an ERB template. Test 3 marshals 500 complex objects. Test 4 sends a large 1MB response. Finally, test 5 sends a very large 10MB response.

WEBrick is evidently slow when compared to its counterparts. Mongrel performs much better that its ancestor and both Thin and Passenger improve over it. Thin is to be the best web server for serving small requests. Passenger, though, is the one to scale better since it performs similarly with 10 or 1000 concurrent users. It also shows better performance when handling large responses. Its performance could be different if it was using Nginx as its back end instead of Apache.  

